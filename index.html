<!doctype html><html lang=en-ca><head><meta charset=utf-8><title>Random Matrix Theory and Machine Learning Tutorial</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="ICML 2021 tutorial on Random Matrix Theory and Machine Learning"><meta name=author content="Fabian Pedregosa, Courtney Paquette, Tom Trogdon, Jeffrey Pennington"><meta name=generator content="Hugo 0.75.1"><link rel=stylesheet href=https://random-matrix-learning.github.io/plugins/bootstrap/bootstrap.min.css><link rel=stylesheet href=https://random-matrix-learning.github.io/plugins/slick/slick.css><link rel=stylesheet href=https://random-matrix-learning.github.io/plugins/themify-icons/themify-icons.css><link rel=stylesheet href=https://random-matrix-learning.github.io/plugins/magnific-popup/magnific-popup.css><link rel=stylesheet href=https://random-matrix-learning.github.io/scss/style.min.css media=screen><link rel="shortcut icon" href=https://random-matrix-learning.github.io/images/favicon.png type=image/x-icon><link rel=icon href=https://random-matrix-learning.github.io/images/favicon.png type=image/x-icon></head><body><div class=preloader></div><div class="main-navigation fixed-top site-header" id=mainmenu-area><nav class="navbar navbar-expand-lg"><div class="container align-items-center"><a class=navbar-brand href=https://random-matrix-learning.github.io><h2 class="mb-0 text-color">Random Matrix Theory and Machine Learning Tutorial</h2></a><button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarmain aria-controls=navbarmain aria-expanded=false aria-label="Toggle navigation">
<span class=ti-menu-alt></span></button><div class="collapse navbar-collapse text-center text-lg-left" id=navbarmain><ul class="navbar-nav ml-auto"><li class=nav-item><a class="nav-link smoth-scroll" href=#chapters>About</a></li><li class=nav-item><a class="nav-link smoth-scroll" href=#reviews>Instructors</a></li><li class=nav-item><a class="nav-link smoth-scroll" href=#contact>Contact</a></li></div></div></nav></div><section class="banner-main py-7" id=banner><div class=container><div class="row justify-content-between"><div class="col-lg-7 col-md-8"><div class=main-banner><span class="text-color font-weight-bold">ICML 2021 tutorial on</span><h1 class="mb-3 mt-2">Random Matrix Theory and Machine Learning</h1><div class=mb-4><h4><span class=text-color></span></h4></div><p class=mb-4>In recent years, random matrix theory (RMT) has come to the forefront of learning theory as a tool to understand some of its most important challenges. From generalization of deep learning models to a precise analysis of optimization algorithms, RMT provides analytically tractable models.</p><a href=#chapters class="btn btn-main mt-2" role=button>Know more <i class="ti-angle-right ml-3"></i></a></div></div></div></div></section><section class="section chapter" id=presentation1><div class=container><div class=row><div class=col-lg-6><div class=section-heading><h2 class=text-lg>First-day presentation</h2><p>g</p></div><iframe src=//www.slideshare.net/slideshow/embed_code/key/9DG5ahkpwpZxtH width=595 height=373 frameborder=0 marginwidth=0 marginheight=0 scrolling=no style="border:1px solid #ccc;border-width:1px;margin-bottom:5px;max-width:100%" allowfullscreen></iframe><div style=margin-bottom:5px><strong><a href=//www.slideshare.net/FabianPedregosa/random-matrix-and-machine-learning-part-1 title="Random Matrix and Machine Learning - Part 1" target=_blank>Random Matrix and Machine Learning - Part 1</a></strong> from <strong><a href=https://www.slideshare.net/FabianPedregosa target=_blank>Fabian Pedregosa</a></strong></div></div></div></div></section><section class="section chapter" id=presentation2><div class=container><div class=row><div class=col-lg-6><div class=section-heading><h2 class=text-lg>First-day presentation 2</h2><p>g</p></div><iframe src=//www.slideshare.net/slideshow/embed_code/key/lqrcDIYulYskwT width=595 height=485 frameborder=0 marginwidth=0 marginheight=0 scrolling=no style="border:1px solid #ccc;border-width:1px;margin-bottom:5px;max-width:100%" allowfullscreen></iframe><div style=margin-bottom:5px><strong><a href=//www.slideshare.net/FabianPedregosa/random-matrix-theory-and-machine-learning-part-2 title="Random Matrix Theory and Machine Learning - Part 2" target=_blank>Random Matrix Theory and Machine Learning - Part 2</a></strong> from <strong><a href=https://www.slideshare.net/FabianPedregosa target=_blank>Fabian Pedregosa</a></strong></div></div></div></div></section><section class="section chapter" id=presentation3><div class=container><div class=row><div class=col-lg-6><div class=section-heading><h2 class=text-lg>First-day presentation 3</h2><p>g</p></div><iframe src=//www.slideshare.net/slideshow/embed_code/key/qK9HNDftMYdpMK width=595 height=485 frameborder=0 marginwidth=0 marginheight=0 scrolling=no style="border:1px solid #ccc;border-width:1px;margin-bottom:5px;max-width:100%" allowfullscreen></iframe><div style=margin-bottom:5px><strong><a href=//www.slideshare.net/FabianPedregosa/random-matrix-theory-and-machine-learning-part-3 title="Random Matrix Theory and Machine Learning - Part 3" target=_blank>Random Matrix Theory and Machine Learning - Part 3</a></strong> from <strong><a href=https://www.slideshare.net/FabianPedregosa target=_blank>Fabian Pedregosa</a></strong></div></div></div></div></section><section class="section chapter" id=presentation4><div class=container><div class=row><div class=col-lg-6><div class=section-heading><h2 class=text-lg>First-day presentation 4</h2><p>g</p></div><iframe src=//www.slideshare.net/slideshow/embed_code/key/M7R22CVxdfo9qM width=595 height=485 frameborder=0 marginwidth=0 marginheight=0 scrolling=no style="border:1px solid #ccc;border-width:1px;margin-bottom:5px;max-width:100%" allowfullscreen></iframe><div style=margin-bottom:5px><strong><a href=//www.slideshare.net/FabianPedregosa/random-matrix-theory-and-machine-learning-part-4 title="Random Matrix Theory and Machine Learning - Part 4" target=_blank>Random Matrix Theory and Machine Learning - Part 4</a></strong> from <strong><a href=https://www.slideshare.net/FabianPedregosa target=_blank>Fabian Pedregosa</a></strong></div></div></div></div></section><section class="section chapter" id=chapters><div class=container><div class=row><div class=col-lg-6><div class=section-heading><h2 class=text-lg>From RMT to ML applications in 4 steps.</h2><p>We will present four talks around two cardinal aspects: (1) introducing tools common in RMT that can be applied to machine learning, and (2) Recent applications of RMT in optimization, generalization, and statistical learning theory.</p></div></div></div><div class=row><div class=col-sm-6><div class=chapter-item><h4>Part 1: Motivating questions</h4><p>Dr. Pedregosa will illustrate how RMT can help us address questions on generalization, overparameterization, double descent, universality of halting time, and ultimately push us beyond the worst-case analysis.</p></div></div><div class=col-sm-6><div class=chapter-item><h4>Part 2: Introduction to random matrix theory</h4><p>Dr. Paquette will introduce the concept of universality of eigenvalue distribution and provide example of concentration for the largest eigenvalue of a random matrix using the power method.</p></div></div><div class=col-sm-6><div class=chapter-item><h4>Part 3: Generalization</h4><p>Dr. Pennington will walk us through random features model and models of double and triple descent.</p></div></div><div class=col-sm-6><div class=chapter-item><h4>Part 4: Analysis of numerical algorithms</h4><p>Dr. Trogdon will explore the topics of average-case analysis and acceleration, as well as concentration.</p></div></div></div></div></section><section class="section-bottom testimonial" id=reviews><div class=container><div class="row justify-content-center"><div class="col-lg-6 col-md-12"><div class="section-heading text-center"><h2 class="mb-3 text-lg">Instructors</h2><p>The field experts that will guide you through random matrix theory in machine learning are</p></div></div></div><div class="row align-items-center"><div class="col-lg-12 col-sm-12 col-md-12 testimonial-wrap"><div class=test-item><div class=testimonial-item-content><div class="test-author-thumb mb-4"><img src=/images/fff.jpeg alt="Testimonial author" class=img-fluid><div class="test-author-info mt-4"><h4 class="mb-0 mt-2">Fabian Pedregosa</h4><p>Research scientist at Google Research Brain</p></div></div><p class=mb-0>Dr. Pedregosa&rsquo;s research has focused in the last years in developing an average-case analysis of optimization algorithms using techniques from random matrix theory. Previously, he has been one of the founding members of the scikit-learn machine learning library. His blog contains several posts on introductory optimization concepts and he has given invited lectures at McGill, UC Berkeley and ENSAE.</p></div></div><div class=test-item><div class=testimonial-item-content><div class="test-author-thumb mb-4"><img src=/images/ppp.jpeg alt="Testimonial author" class=img-fluid><div class="test-author-info mt-4"><h4 class="mb-0 mt-2">Courtney Paquette</h4><p>Assistant professor at McGill University</p></div></div><p class=mb-0>Dr. Paquette’s research broadly focuses on designing and analyzing algorithms for large-scale optimization problems, motivated by applications in data science. Her recent work has focused on average-case complexity that combined aspects of optimization and random matrix theory. She is a CIFAR Canada AI chair with the Quebec AI institute (MILA).</p></div></div><div class=test-item><div class=testimonial-item-content><div class="test-author-thumb mb-4"><img src=/images/ttt.jpeg alt="Testimonial author" class=img-fluid><div class="test-author-info mt-4"><h4 class="mb-0 mt-2">Thomas Trogdon</h4><p>Associate professor at University of Washington</p></div></div><p class=mb-0>Dr. Trogdon’s work focuses on connections between classical algorithms from numerical linear algebra and random matrix theory. He is a core member of a group of researchers that have, first, discovered that the runtimes of algorithms exhibit universal distributions, and second, began rigorously establishing theorems.</p></div></div><div class=test-item><div class=testimonial-item-content><div class="test-author-thumb mb-4"><img src=/images/jjj.jpeg alt="Testimonial author" class=img-fluid><div class="test-author-info mt-4"><h4 class="mb-0 mt-2">Jeffrey Pennington</h4><p>Research scientist at Google Research Brain</p></div></div><p class=mb-0>Dr. Pennington&rsquo;s current research interests center on the theory of deep learning, and include topics such as random matrix theory and generalization in high dimensions, the role of overparameterization, wide neural networks and their corresponding kernels, the dynamics of learning, and the geometry of high-dimensional loss surfaces.</p></div></div></div></div></div></section><section class="section contact" id=contact><div class=container><div class="row justify-content-center"><div class="col-md-12 col-lg-8"><div class="section-heading text-center"><h2 class="mb-2 text-lg">Contact Us</h2><p>Whether you have questions or you would just like to say hello, feel free to reach out.</p></div></div></div><div class=row><div class="col-lg-4 col-sm-6"><div class="contact-info-block text-center mb-4"><i class=ti-world></i><p class=mb-0>ICML 2021 main website</p><h5><a href=https://icml.cc/>icml.cc</a></h5></div></div><div class="col-lg-4 col-sm-6"><div class="contact-info-block text-center mb-4"><i class=ti-email></i><p class=mb-0>Email</p><h5>pedregosa [at] google [dot] com</h5></div></div><div class="col-lg-4 col-sm-6"><div class="contact-info-block text-center mb-4"><i class=ti-help></i><p class=mb-0>Need help?</p><h5>Read this <a href=https://icml.cc/FAQ>FAQ</a> or contact the ICML <a href=https://icml.cc/Help/Contact>help desk</a></h5></div></div></div></div></section><footer class=footer><div class=container><div class="row justify-content-between align-items-center"><div class="col-lg-6 col-sm-12"><div class=footer-widget><a class="mb-4 d-inline-block" href=https://random-matrix-learning.github.io><h2 class="mb-0 text-dark">Random Matrix Theory and Machine Learning Tutorial</h2></a><p class=mb-4></p></div></div></div></div><div class=container><div class="row footer-btm mt-5 pt-4 border-top"><div class=col-lg-6><p class=footer-copy>© RMT+ML</p></div></div></div></footer><script src=https://random-matrix-learning.github.io/plugins/jQuery/jquery.min.js></script><script src=https://random-matrix-learning.github.io/plugins/bootstrap/bootstrap.min.js></script><script src=https://random-matrix-learning.github.io/plugins/slick/slick.min.js></script><script src=https://random-matrix-learning.github.io/plugins/magnific-popup/magnific-popup.min.js></script><script src=https://random-matrix-learning.github.io/js/script.min.js></script></body></html>