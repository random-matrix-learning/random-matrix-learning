########################## Banner #############################
banner:
  enable: true
  writter: "ICML 2021 tutorial on"
  title: "Random Matrix Theory and Machine Learning"
  image: "images/logo.png"
  content: |
    In recent years, random matrix theory (RMT) has come to the forefront of learning theory as a tool to understand some of its most important challenges. From generalization of deep learning models to a precise analysis of optimization algorithms, RMT provides analytically tractable models.
 # price: "2020ish"
  button: Know more


######################### Chapters ##########################
chapters:
  enable: true
  title: "Random Matrix Theory in Machine Learning tutorial."
  subtitle: "We will present four talks around two cardinal aspects: 
  (1) introducing tools common in RMT that can be applied to machine learning, 
  and (2) Recent applications of RMT in optimization, generalization, and statistical learning theory. The tutorial is divided into 4 parts of roughly 30 min each. "
  chapter:
    # chapter preview loop
    - title: "Part 1: Introduction and Classical Random Matrix Theory Ensembles"
      content:
        "This section introduces two of the classical Random Matrix Theory ensembles: the Gaussian Orthogonal Ensemble and Wishart matrices. We'll see the emergence of the semi-circle and Marchenko-Pastur distributions from simple experiments on these matrices. [More ...](#presentation1)"

    # chapter preview loop
    - title: "Part 2: Introduction to Random Matrix Theory, the Stieltjes and R Transform"
      content:
        "This section introduces some two very powerful objects in random matrix theory: the Stieltjes and R transform. We'll see how to use them to construct increasingly complex ensembles and discuss some recent topics in random matrix theory such as freeness. [More ...](#presentation2)"

    # chapter preview loop
    - title: "Part 3: Analysis of Numerical Algorithms"
      content:
        "This section is devoted to applications of random matrix theory into the analysis of numerical algorithms. We'll see how random matrix theory allows to avoid the pitfals of a worst-case analysis and why the time it takes for an algorithm to return a solution seems to be only mildly dependent on the data distribution over the inputs, a phenomenon known as halting time universality. [More ...](#presentation3)"

    # chapter preview loop
    - title: "Part 4: The Mystery of Generalization: Why Does Deep Learning Work?"
      content:
        "This section discusses random matrix theory models of generalization in Deep Neural Networks. We'll see how these models can be used to study some of the most puzzling behaviors of deep neural networks, such as double (and triple) descent. [More ...](#presentation4)"

###### SLIDES ######

presentation1:
  enable: true
  title: "Part 1: Introduction and Classical Random Matrix Theory Ensembles"
  subtitle: "This section introduces two of the classical Random Matrix Theory ensembles, the Gaussian Orthogonal Ensembleand Wishart matrices. Through numerical experiments, we'll motivate some of the most important distributions in random matrix theory such as the semi-circle and Marchenko-Pastur, as well as key concepts such as universality."
  
  links: "[**Slides PDF**](/pdf/part1.pdf) | [**Slides source code**](https://github.com/random-matrix-learning/slides) |  [**Experiments (Colab)**](https://colab.research.google.com/drive/1Lver5l_9kaWviOW6C2SbCS4y2PTmZOel?usp=sharing) | [Video with Slides](https://slideslive.com/38959830)"





presentation2:
  enable: true
  title: "Part 2. Introduction to Random Matrix Theory: the Stieltjes and R Transform"
  subtitle: "This section introduces some core proof techniques in random matrix theory: the Stieltjes and R transform.
        Through experiments, we will illustrate how to use these objects to compute spectral properties of increasingly complex random matrix ensembles. We'll also discuss some recent topics in random matrix theory such as freeness."

  links: "[**Slides PDF**](/pdf/part2.pdf) | [**Slides source code**](https://github.com/random-matrix-learning/slides) | [**Experiments R-Transform** (by Ria Stevens)](https://colab.research.google.com/github/RiaStevens/rmt-research/blob/main/RMT_Sim_Plots.ipynb) | [**Experiments Stieltjes Transform** (by Elliot Paquette)](https://colab.research.google.com/drive/1JZQbdLBJTg3pFEKP2k0vEnL9J4spz8fK?usp=sharing) | [Video with Slides](https://slideslive.com/38959830)"
 
presentation3:
  enable: true
  title: Part 3. Analysis of Numerical Algorithms
  subtitle:  "This section is devoted to applications of random matrix theory into the analysis of numerical algorithms. We'll see how random matrix theory allows to avoid the pitfals of a worst-case analysis and why the time it takes for an algorithm to return a solution seems to be only mildly dependent on the data distribution over the inputs, a phenomenon known as halting time universality."

  links: "[**Slides PDF**](/pdf/part3.pdf) | [**Slides source code**](https://github.com/random-matrix-learning/slides) |  [**Experiments (Colab)**](https://colab.research.google.com/drive/1UZRSK665b8sqq0NQFwMCwrVabPlB-7nK?usp=sharing) | [Video with Slides](https://slideslive.com/38962481)"

presentation4:
  enable: true
  title: "Part 4. The Mystery of Generalization: Why Does Deep Learning Work?"
  subtitle:   "This section discusses random matrix theory models of generalization in Deep Neural Networks. We'll see how these models can be used to study some of the most puzzling behaviors of deep neural networks, such as double (and triple) descent. "

  links: "[**Slides PDF**](/pdf/part4.pdf) | [**Slides source code**](https://github.com/random-matrix-learning/slides) | [Video with Slides](https://slideslive.com/38962482)"



presentation5:
  enable: true
  title: To know more ...
  subtitle: "This tutorial is meant as an introduction to the field of random matrix theory for machine learning researchers. Those wanting to deepen their understanding might be interested in the following references.

  
  Textbooks on random matrix theory:

    * Tao, Terence. _Topics in random matrix theory_. American Mathematical Soc., 2012. [[PDF]](https://web.archive.org/web/20170922002846id_/https://terrytao.files.wordpress.com/2011/02/matrix-book.pdf)

    * Bai, Zhidong, and Jack W. Silverstein. _Spectral analysis of large dimensional random matrices_. Vol. 20. New York: Springer, 2010. [[Springer]](http://dx.doi.org/10.1007/978-1-4419-0661-8).
  
  
  Textbook on random matrix theory for machine learning:

    * Romain Couillet, Zhenyu Liao. _Random Matrix Theory for Machine Learning_, 2021 [[PDF]](https://zhenyu-liao.github.io/pdf/RMT4ML.pdf), [[Webpage]](https://zhenyu-liao.github.io/book/)
    
  The full list of references used in the slides can be found <a href="https://random-matrix-learning.github.io/images/references.html">here</a>
  "


########################## Revews ###########################
reviews:
  enable: true
  title: "Instructors"
  subtitle: "The researchers that will guide you through this tutorial are"
  review:
    # review item loop
    - name: "Fabian Pedregosa"
      image: "images/fff.jpeg" # image size 80*80 px
      designation: "Research scientist at Google Research"
      content:
        "Fabian Pedregosa's research has focused in the last years in developing an
        average-case analysis of optimization algorithms using techniques from random matrix theory. 
        Previously, he has done research in projection-free and asynchronous optimizationbeen. He is also
        one of the founding members of the scikit-learn machine learning library. [Webpage](http://fa.bianp.net)."

    # review item loop
    - name: "Courtney Paquette"
      image: "images/ppp.jpeg" # image size 80*80 px
      designation: "Assistant professor at McGill University"
      content:
        "Courtney Paquette’s research broadly focuses on designing and analyzing algorithms 
        for large-scale optimization problems, motivated by applications in data science. 
        Her recent work has focused on average-case complexity that combined aspects of optimization and random matrix theory. 
        She is a CIFAR Canada AI chair with the Quebec AI institute (MILA)."

    # review item loop
    - name: "Thomas Trogdon"
      image: "images/ttt.jpeg" # image size 80*80 px
      designation: "Associate professor at University of Washington"
      content:
         "Tom Trogdon’s work focuses on connections between classical algorithms
         from numerical linear algebra and random matrix theory. He is a core member of a
         group of researchers that have, first, discovered that the runtimes of algorithms exhibit
         universal distributions, and second, began rigorously establishing theorems."

      # review item loop
    - name: "Jeffrey Pennington"
      image: "images/jjj.jpeg" # image size 80*80 px
      designation: "Research scientist at Google Research"
      content:
        "Jeffrey Pennington's current research interests center on the theory of deep learning, 
        and include topics such as random matrix theory and generalization in high dimensions, 
        the role of overparameterization, wide neural networks and their corresponding kernels, 
        the dynamics of learning, and the geometry of high-dimensional loss surfaces."

# #################################### device ################################
# devices:
#   enable: true
#   title: "Schedule"
#   content:
#     "Find our schedule on Google Calendar
#     [here](https://calendar.google.com/calendar/embed?height=600&wkst=1&bgcolor=%23ffffff&ctz=America%2FToronto&src=dTM2ZGgydWRsODdjNmFtYXMyb3Rha2RobmtAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&color=%23AD1457)!"
  # image : "images/about/ipad.jpg"
  # content:
  # feature item loop
#    - title : "Take a sneak peak insight"
#      icon : "ti-bar-chart" # themify icon pack : https://themify.me/themify-icons
#      content : "Sed laborum omnis earum facere culpa optio natus quaerat minus."

#    # feature item loop
#    - title : "Reporting & Analysis"
#      icon : "ti-write" # themify icon pack : https://themify.me/themify-icons
#      content : "Sed laborum omnis earum facere culpa optio natus quaerat minus."#
##
#

# button
# button:
#   enable : false
#   label : "Spotify"
#   link : "<iframe src="https://open.spotify.com/embed/playlist/1Bl4wHCS7C6FpWockoXoby" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>"

######################################## author #############################
#playlist:
#  enable : false
#  #image : "images/about/home-1.jpg"
#  title: "Spotify playlist"
#  #designation : ""
#  content : "Checkout the Brainhack playlist for music to hack to"

# button
# button:
#   enable : false
#   label : "Spotify"
#   link : "<iframe src="https://open.spotify.com/embed/playlist/1Bl4wHCS7C6FpWockoXoby" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>"

# ################################ Awards #####################################
# awards:
#   enable: true
#   title: "Brought to you by"
#   award:
#     # award item loop
#     - title: "Valentina Borghesani"
#       image: "images/client/vale.jpg"

#     # award item loop
#     - title: "Samuel Guay"
#       image: "images/client/sam.png"

#     # award item loop
#     - title: "Désirée Lussier"
#       image: "images/client/lussier.jpeg"

#     # award item loop
#     - title: "And all the Brainhack Team!"
#       image: "images/logo.png"

# ############################# Other books ###############################
# otherBooks:
#   enable: true
#   title: "Friends & sponsors"
#   subtitle: "We acknowlege the generous support of"
#   book:
#     # books loop
#     - image: "images/client/udem.png"
#       link: "https://www.umontreal.ca/"

#     # books loop
#     - image: "images/client/mcgiill.png"
#       link: "https://www.mcgill.ca/"

#     # books loop
#     - image: "images/client/concordia.png"
#       link: "https://www.concordia.ca/"

# # ################################ Blog ###################################
# blog:
#   enable: true
#   title: "Projects"
#   subtitle: "Feel free to join any project you are interested in!"
# # blog post comes from 'content/blog'

################################# Contact ##############################
contact:
  enable: true
  title: "Contact Us"
  subtitle:
    "Whether you have questions or you would just like to say hello, feel free
    to reach out."
  contactItem:
    # contact Item loop
    # - title: "ICML 2021 tutorial website"
    #   icon: "ti-world" # themify icon pack : https://themify.me/themify-icons
    #   list:
    #     - listItem: "[icml.cc](https://icml.cc/Conferences/2021/Schedule?showEvent=10840)"

    - title: "ICML 2021 tutorial website"
      icon: "ti-world" # themify icon pack : https://themify.me/themify-icons
      list:
        - listItem: "[icml.cc](https://icml.cc/virtual/2021/tutorial/10840)"


    # contact Item loop
    - title: "Found a mistake in the materials?"
      icon: "ti-github" # themify icon pack : https://themify.me/themify-icons
      list:
        - listItem: "Please report the issue [here](https://github.com/random-matrix-learning/slides/issues)"

    # contact Item loop
    - title: "Need help?"
      icon: "ti-help" # themify icon pack : https://themify.me/themify-icons
      list:
        - listItem:
            "Read this [FAQ](https://icml.cc/FAQ) or contact the ICML
            [help desk](https://icml.cc/Help/Contact)"
